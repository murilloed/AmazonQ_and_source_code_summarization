# ğŸ§  AvaliaÃ§Ã£o de LLMs na DocumentaÃ§Ã£o Automatizada de CÃ³digo Java
### RepositÃ³rio Experimental â€“ Murillo (2025)

Este repositÃ³rio contÃ©m os artefatos e scripts necessÃ¡rios para **replicar o processo de geraÃ§Ã£o, anÃ¡lise e aprimoramento de documentaÃ§Ã£o tÃ©cnica automatizada** utilizando **Amazon Q Developer** e **ChatGPT (LLM-as-a-Judge)**.  
Os experimentos seguem o modelo metodolÃ³gico descrito no projeto de qualificaÃ§Ã£o *Murillo2_qualifica (2025)*.

---

## ğŸ§© SumÃ¡rio
- [Objetivo da Pesquisa](#objetivo-da-pesquisa)
- [Arquitetura Experimental](#arquitetura-experimental)
- [Estrutura do RepositÃ³rio](#estrutura-do-repositÃ³rio)
- [Pipeline de ExecuÃ§Ã£o](#pipeline-de-execuÃ§Ã£o)
- [Reprodutibilidade](#reprodutibilidade)
- [Resultados](#resultados)
- [CitaÃ§Ã£o e LicenÃ§a](#citaÃ§Ã£o-e-licenÃ§a)

---

## ğŸ¯ Objetivo da Pesquisa
Investigar a **eficÃ¡cia de modelos de linguagem (LLMs)** na geraÃ§Ã£o automÃ¡tica de documentaÃ§Ã£o tÃ©cnica para sistemas Java legados.  
O estudo busca quantificar ganhos de:
- **Completude (C)** â€“ presenÃ§a de informaÃ§Ãµes essenciais;
- **Utilidade (H)** â€“ clareza e relevÃ¢ncia para desenvolvedores;
- **Veracidade (T)** â€“ aderÃªncia ao comportamento real do cÃ³digo.

A metodologia combina **Amazon Q (geraÃ§Ã£o)** e **ChatGPT (avaliaÃ§Ã£o e refinamento)** em um ciclo iterativo baseado em mÃ©tricas CHT (*Completenessâ€“Helpfulnessâ€“Truthfulness*).

---

## âš™ï¸ Arquitetura Experimental

```mermaid
graph TD
A[CÃ³digo Original] --> B[Amazon Q - Few Shot Prompting]
B --> C[DocumentaÃ§Ã£o Inicial (Javadoc)]
C --> D[ChatGPT - LLM-as-a-Judge]
D --> E[MÃ©tricas CHT e Feedback]
E --> F[Amazon Q - Refinamento Iterativo]
F --> G[VersÃ£o Final da DocumentaÃ§Ã£o]
G --> H[Evaluation Framework - MÃ©tricas Agregadas]
H --> I[Survey de Desenvolvedores]
ğŸ“ Estrutura do RepositÃ³rio
css
Copiar cÃ³digo
murillo-llm-code-docs/
â”‚
â”œâ”€â”€ README.md                â† Documento principal
â”œâ”€â”€ LICENSE                  â† LicenÃ§a MIT
â”œâ”€â”€ CITATION.cff             â† Metadados de citaÃ§Ã£o (Zenodo)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ codigo_original/     â† CÃ³digo-fonte Java sem documentaÃ§Ã£o
â”‚   â”œâ”€â”€ codigo_amazonq/      â† SaÃ­da inicial do Amazon Q
â”‚   â”œâ”€â”€ codigo_final/        â† VersÃ£o refinada (Q + ChatGPT)
â”‚   â”œâ”€â”€ results/             â† GrÃ¡ficos, mÃ©tricas e tabelas (CHT)
â”‚   â””â”€â”€ survey/              â† Dados simulados de validaÃ§Ã£o humana
â”‚
â”œâ”€â”€ methodology/
â”‚   â”œâ”€â”€ 01_pipeline_overview.md
â”‚   â”œâ”€â”€ 02_prompt_amazonq_fewshot.md
â”‚   â”œâ”€â”€ 03_prompt_chatgpt_eval.md
â”‚   â”œâ”€â”€ 04_prompt_amazonq_refinement.md
â”‚   â”œâ”€â”€ 05_framework_cht.md
â”‚   â””â”€â”€ 06_survey_procedure.md
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_ast.py
â”‚   â”œâ”€â”€ analyze_completeness_regex.py
â”‚   â”œâ”€â”€ compute_cht_metrics.py
â”‚   â”œâ”€â”€ plot_results.py
â”‚   â””â”€â”€ llm_as_judge_chatgpt.ipynb
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ pipeline_demonstration.ipynb
ğŸš€ Pipeline de ExecuÃ§Ã£o
1ï¸âƒ£ Preparar ambiente
Requer:

Python 3.10+

API OpenAI (GPT-4)

Acesso ao Amazon Q Developer

DependÃªncias:

bash
Copiar cÃ³digo
pip install openai matplotlib pandas python-docx
2ï¸âƒ£ Executar etapas principais
bash
Copiar cÃ³digo
# 1. GeraÃ§Ã£o inicial (Few-Shot)
python scripts/generate_ast.py

# 2. AvaliaÃ§Ã£o ChatGPT (LLM-as-a-Judge)
jupyter notebook notebooks/pipeline_demonstration.ipynb

# 3. CÃ¡lculo das mÃ©tricas CHT
python scripts/compute_cht_metrics.py

# 4. Plotagem dos resultados
python scripts/plot_results.py
ğŸ“Š Resultados
DimensÃ£o	Antes da RevisÃ£o	ApÃ³s RevisÃ£o	VariaÃ§Ã£o
Completeness	0.6	0.8	+33%
Helpfulness	2.4	4.2	+75%
Truthfulness	1.0	1.0	0%

<p align="center"> <img src="data/results/CHT_Method1_comparison.png" width="550"> </p>
ConclusÃ£o:
O ciclo iterativo Amazon Q â†’ ChatGPT â†’ Amazon Q elevou em mais de 70% a clareza e utilidade das documentaÃ§Ãµes, sem perda de precisÃ£o tÃ©cnica.

ğŸ§ª Reprodutibilidade
Todos os prompts e scripts sÃ£o disponibilizados integralmente na pasta methodology/.
Cada arquivo possui cabeÃ§alho com metadados de:

Autor e afiliaÃ§Ã£o acadÃªmica;

Data e versÃ£o;

Linguagem;

DescriÃ§Ã£o do propÃ³sito cientÃ­fico.

Para replicar o experimento com outro mÃ©todo Java, basta substituir o arquivo de entrada em data/codigo_original/ e executar o mesmo pipeline.

ğŸ“š ReferÃªncia cientÃ­fica
Murillo, M. (2025). AvaliaÃ§Ã£o de LLMs na GeraÃ§Ã£o de DocumentaÃ§Ã£o TÃ©cnica Automatizada de Sistemas Java Legados.
Projeto de QualificaÃ§Ã£o â€” Programa de PÃ³s-GraduaÃ§Ã£o em ComputaÃ§Ã£o Aplicada, Universidade Federal XYZ.

ğŸ§© CitaÃ§Ã£o e LicenÃ§a
Cite este repositÃ³rio como:

bash
Copiar cÃ³digo
@software{murillo2025_llm_docs,
  author = {Murillo, M.},
  title  = {AvaliaÃ§Ã£o de LLMs na DocumentaÃ§Ã£o Automatizada de CÃ³digo Java},
  year   = {2025},
  url    = {https://github.com/usuario/murillo-llm-code-docs},
  version = {1.0},
  doi = {10.5281/zenodo.placeholder}
}
ğŸ“„ LicenÃ§a: MIT

ğŸ¤ Contato
Autor: Murillo Carvalho
E-mail: murillo.ed1402@gmail.com
LinkedIn: linkedin.com/in/murillo-carvalho
